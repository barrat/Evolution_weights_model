{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import pandas as pd \n",
    "import os\n",
    "import json \n",
    "import networkx as nx \n",
    "import seaborn as sns\n",
    "\n",
    "from datetime import datetime\n",
    "from dateutil.parser import parse\n",
    "from collections import Counter\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computation of Evolving weights \n",
    "Data : proximity contacts data\n",
    "- Definition of the algorithm of computation of weights\n",
    "- Processing of the data \n",
    "- Defining parameters\n",
    "- Running the algorithm on the processed data for different values of the parameters\n",
    "- Extracting and plotting weights evolution for a sample "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNCTION DEFINITION\n",
    "Inputs: \n",
    "- contacts data \n",
    "- parameters of the model \n",
    "- Final time resolution (expressed in hours), i.e. setting the timestamps\n",
    "- Starting time of the perturbation (index of timestamp)\n",
    "- Ending time of the perturbation (index of timestamp)\n",
    "- Dictionary with the rule for the perturbation: individuals to be switched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PERTURBATIONS short durations, with n_hours timespan, choosing t_switch and reswitch based on the timespan \n",
    "def evolution_perturbed_weights(contacts,alpha,beta,n_hours,t0,t1,d_switch,d_reswitch):\n",
    "    \n",
    "    # Set max value for the weights\n",
    "    wmax = 1\n",
    "    \n",
    "    # Define nodes starting from interacting individuals\n",
    "    nodes = set(contacts.i.unique()).union(set(contacts.j.unique()))\n",
    "    N = len(nodes)\n",
    "    \n",
    "    \n",
    "    \n",
    "    dates = sorted(contacts.Date.unique())\n",
    "    \n",
    "    contacts['timespan'] = contacts['interval'].map(lambda x: x//(180*n_hours)+1) \n",
    "    \n",
    "    #Times of start and end of the perturbation expressed in index of the 20s interval \n",
    "    t_switch = contacts[contacts['timespan'] == contacts.timespan.unique()[t0]].iloc[0]['interval']\n",
    "\n",
    "    t_reswitch = contacts[contacts['timespan'] == contacts.timespan.unique()[t1]].iloc[0]['interval']\n",
    "\n",
    "\n",
    "    #generate a dictionary of complete directed graphs, one for each time interval of 20seconds\n",
    "    G_p = {}\n",
    "\n",
    "    # generate another dictionary of graphs that saves the graph at the end of each day\n",
    "    g_p = {}\n",
    "\n",
    "    #inizialize the time\n",
    "    curr_timespan = contacts.timespan.unique()[0]\n",
    "\n",
    "\n",
    "    #inizialize weigths (at zero)\n",
    "    G_p[0] = nx.complete_graph(nodes, nx.DiGraph())\n",
    "\n",
    "    for source, target in G_p[0].edges():\n",
    "        G_p[0][source][target]['weight'] = 0\n",
    "\n",
    "\n",
    "    # loop on the single 20s intervals, i.e. resolution of the contacts data \n",
    "    for interval in range(len(contacts.interval.unique())):\n",
    "\n",
    "        t = contacts.interval.unique()[interval]\n",
    "\n",
    "        # PERTURBATION\n",
    "        ##########################################################################\n",
    "        if t == t_switch:\n",
    "\n",
    "            print t_switch\n",
    "            print contacts[contacts['interval']==t].iloc[0]['Date']\n",
    "\n",
    "            contacts['i'] = contacts.i.apply(lambda x : d_switch[x] if x in d_switch else x)\n",
    "            contacts['j'] = contacts.j.apply(lambda x : d_switch[x] if x in d_switch else x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if t == t_reswitch:\n",
    "\n",
    "            print t_reswitch\n",
    "            print contacts[contacts['interval']==t].iloc[0]['Date']\n",
    "\n",
    "            contacts['i'] = contacts.i.apply(lambda x : d_reswitch[x] if x in d_reswitch else x)\n",
    "            contacts['j'] = contacts.j.apply(lambda x : d_reswitch[x] if x in d_reswitch else x)\n",
    "        #############################################################################\n",
    "\n",
    "\n",
    "        # define the precedent t\n",
    "        if interval == 0:\n",
    "            t_prec = 0\n",
    "        else:\n",
    "            t_prec = contacts.interval.unique()[interval-1]\n",
    "\n",
    "        # select interval \n",
    "        contacts_i = contacts[contacts['interval'] == t]\n",
    "        \n",
    "        # INSTANTANEOUS NETWORK\n",
    "        #############################################################################\n",
    "\n",
    "        '''\n",
    "        We define an instantaneous network including just the interacting nodes.\n",
    "        The links of this instantaneous network have to be excluded from the updating of the weights.\n",
    "        The rule of updating of the weights assumes that we can define the temporal succession \n",
    "        of the interactions.\n",
    "        Since these interactions happen at the same times, the rule would be ambiguous.\n",
    "        '''\n",
    " \n",
    "        # temporary nodes\n",
    "        nodes_t = set(contacts_i.i.unique()).union(set(contacts_i.j.unique()))\n",
    "\n",
    "        # temporary undirected network  \n",
    "        G_i = nx.from_pandas_edgelist(contacts_i,'i','j')\n",
    "        ##############################################################################\n",
    "        \n",
    "        # for each interval, form a directed network\n",
    "        G_p[t] = nx.complete_graph(nodes, nx.DiGraph())\n",
    "\n",
    "        # update weights with the precedent \n",
    "        for source, target in G_p[t].edges():\n",
    "            G_p[t][source][target]['weight'] = G_p[t_prec][source][target]['weight']\n",
    "\n",
    "        #Check if the timespan has changed\n",
    "        #At the end of the timespan, save current weights\n",
    "        if len(contacts_i) == 1:\n",
    "            timespan = contacts_i.timespan.item()\n",
    "        else: #len(contacts_i) > 1:\n",
    "            timespan = contacts_i.timespan.iloc[0]\n",
    "\n",
    "\n",
    "        if timespan != curr_timespan:\n",
    "            print timespan, curr_timespan\n",
    "            g_p[curr_timespan] = G_p[t]\n",
    "            curr_timespan = timespan\n",
    "\n",
    "        # update weights of g[t], reinforcement for interacting nodes \n",
    "        for i in G_i.nodes():\n",
    "            for j in G_i.neighbors(i):\n",
    "                G_p[t][i][j]['weight']=G_p[t][i][j]['weight'] + alpha*(wmax - G_p[t][i][j]['weight'])\n",
    "\n",
    "\n",
    "            #update weights of g[t], decay for non-interacting nodes\n",
    "            for k in G_p[t].neighbors(i):\n",
    "                if k in G_i.neighbors(i):\n",
    "                    continue\n",
    "                G_p[t][i][k]['weight'] = G_p[t][i][k]['weight']*(1 - beta)  \n",
    "        #last day \n",
    "        if t == contacts.interval.unique()[-1]:  \n",
    "            g_p[curr_timespan] = G_p[t]\n",
    "\n",
    "    return g_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to datetime\n",
    "from time import strftime, localtime\n",
    "\n",
    "def convert_epoch_to_local(epoch):\n",
    "    '''Converting epoch to local time'''\n",
    "    return strftime('%Y-%m-%d %H:%M:%S', localtime(epoch))\n",
    "\n",
    "check = convert_epoch_to_local(1529496380)\n",
    "print(check), type(check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DICTIONARY OF NAMES-TAGS after June 11 2019  \n",
    "\n",
    "f = open('Data/dictionary_tags_names_june_11_2019.json')\n",
    "tags_to_names = json.load(f)\n",
    "print(tags_to_names)\n",
    "names_to_tags = {}\n",
    "for tag in tags_to_names:\n",
    "    name = (tags_to_names[tag]) \n",
    "    names_to_tags[name] = int(tag)\n",
    "print(names_to_tags)\n",
    "\n",
    "\n",
    "#CHANGE KEYS IN INT \n",
    "for k in tags_to_names:\n",
    "    tags_to_names[int(k)] = tags_to_names.pop(k)\n",
    "tags_to_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHOOSE FILES\n",
    "\n",
    "PATH = 'Data/Contacts'\n",
    "FILES = os.listdir(PATH)\n",
    "\n",
    "#Import contacts and merge contacts of all the contacts files \n",
    "\n",
    "list_df = []\n",
    "for el in FILES:\n",
    "    \n",
    "    filename = PATH+el\n",
    "\n",
    "    df_rfid = pd.read_csv(filename, compression = None, index_col = False,sep = ' ',names=['t','i','j'])\n",
    "    df_rfid = df_rfid[(df_rfid['i'].isin(tags_to_names)) & (df_rfid['j'].isin(tags_to_names))]\n",
    "    \n",
    "    \n",
    "    df_rfid['DateTime'] = df_rfid['t'].map(lambda x: convert_epoch_to_local(x))\n",
    "    df_rfid['DateTime'] = pd.to_datetime(df_rfid['DateTime'])\n",
    "    df_rfid.sort_values('DateTime')\n",
    "    df_rfid['Date'] = df_rfid['DateTime'].map(lambda x: datetime.strftime(x, '%Y-%m-%d'))\n",
    "    list_df.append(df_rfid)\n",
    "\n",
    "contacts = pd.concat(list_df)\n",
    "contacts = contacts.sort_values('DateTime')\n",
    "\n",
    "# DIVIDE THE CONTACTS IN TIME WINDOWS OF 20 SECONDS AND ASSIGN THE APPROPRIATE INDEX TO EACH CONTACT \n",
    "t0 = contacts.iloc[0]['t']\n",
    "t_end = contacts.iloc[-1]['t']\n",
    "\n",
    "\n",
    "contacts['interval'] = contacts.t.map(lambda x: (x-t0)//20+1)\n",
    "contacts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHOOSE A DAY AND SET THE TIME RESOLUTION\n",
    "day = '2019-06-25'\n",
    "#contacts = pd.concat(list_df)\n",
    "#contacts = contacts.sort_values('DateTime')\n",
    "contacts_ = contacts[contacts['Date'] == day]\n",
    "t0 = contacts_.iloc[0]['t']\n",
    "#contacts_['interval'] = contacts_.t.map(lambda x: (x-t0)//20+1)\n",
    "contacts_.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INPUT SETTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ind1 = 1712\n",
    "ind2 = 1789\n",
    "\n",
    "d_switch = {ind1 : ind2, ind2 : ind1}\n",
    "d_reswitch = {ind1 : ind2, ind2 : ind1}\n",
    "\n",
    "tp0 = 6\n",
    "tp1 = 10 \n",
    "\n",
    "alpha = 0.1\n",
    "beta1=alpha*10\n",
    "beta2=alpha*5\n",
    "beta3 = alpha*2\n",
    "n_hours = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run the algorithm on the data \n",
    "g = evolution_perturbed_weights(contacts_, alpha, alpha, n_hours, tp0, tp1, d_switch, d_reswitch)\n",
    "g1 = evolution_perturbed_weights(contacts_, alpha,beta1, n_hours, tp0, tp1, d_switch, d_reswitch)\n",
    "g2 = evolution_perturbed_weights(contacts_, alpha,beta2, n_hours, tp0, tp1, d_switch, d_reswitch)\n",
    "g3 = evolution_perturbed_weights(contacts_, alpha,beta3, n_hours, tp0, tp1, d_switch, d_reswitch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listtimes = sorted(g.keys())\n",
    "edges = g[listtimes[0]].edges()\n",
    "weights = {}\n",
    "weights1= {}\n",
    "weights2 = {}\n",
    "weights3 = {}\n",
    "for e in edges:\n",
    "    weights[e] = []\n",
    "    weights1[e] = []\n",
    "    weights2[e] = []\n",
    "    weights3[e] = []\n",
    "    for t in listtimes:\n",
    "        weights[e].append(g[t][e[0]][e[1]]['weight'])\n",
    "        weights1[e].append(g1[t][e[0]][e[1]]['weight'])\n",
    "        weights2[e].append(g2[t][e[0]][e[1]]['weight'])\n",
    "        weights3[e].append(g3[t][e[0]][e[1]]['weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#choose the strongest links, i.e. links with the average highest weight or select a set of links\n",
    "avg_weights = {l: np.mean(weights[l]) for l in weights}\n",
    "max_weights = {l: max(weights[l]) for l in weights}\n",
    "ranking  = sorted(max_weights.items(), key=operator.itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_set_ranked = [w[0] for w in ranking]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_set = [\n",
    "    (1522, 1712),\n",
    "    (1712, 1522),\n",
    "    (1789, 1522),\n",
    "    (1522, 1789),\n",
    "    (1789, 1872),\n",
    "    (1480, 1789),\n",
    "    (1712, 1872),\n",
    "    (1872, 1789),\n",
    "    (1069, 1712),\n",
    "    (1435, 1712),\n",
    "    (1435, 1789),\n",
    "    (1057, 1712),\n",
    "    (1789, 1435),\n",
    "    (1712, 1057),\n",
    "    (1789, 1480),\n",
    "    (1712, 1520),\n",
    "    (1872, 1712),\n",
    "    (1520, 1712),\n",
    "    (1712, 1435),\n",
    "    (1712, 1069),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAJECTORIES OF SINGLE WEIGHTS\n",
    "fig = plt.figure(figsize=(10,7))\n",
    "i=1\n",
    "                 \n",
    "for edge in filtered_set_ranked[:9]:\n",
    "    ax = fig.add_subplot(3,3,i)\n",
    "    if i==9:\n",
    "        ax.plot(weights[edge], '.-', label='1 PARAMETER') \n",
    "        ax.plot(weights1[edge], '.-', label=r'$\\alpha$*10' ) \n",
    "        ax.plot(weights2[edge], '.-', label=r'$\\alpha$*5') \n",
    "        ax.plot(weights3[edge], '.-', label=r'$\\alpha$*2')\n",
    "        plt.axvline(x=tp0, color='orange', label='node switching')\n",
    "        plt.axvline(x=tp1, color='blue', label='node RE-switching')\n",
    "    else:\n",
    "        ax.plot(weights[edge], '.-')\n",
    "        ax.plot(weights1[edge], '.-')\n",
    "        ax.plot(weights2[edge], '.-')\n",
    "        ax.plot(weights3[edge], '.-')\n",
    "        \n",
    "        plt.axvline(x=tp0, color='orange')\n",
    "        plt.axvline(x=tp1, color='blue')\n",
    "   \n",
    "\n",
    "    plt.ylabel('Weight', fontsize=16)\n",
    "    ax.set_title(tags_to_names[edge[0]]+'-'+tags_to_names[edge[1]])\n",
    "    plt.tight_layout()\n",
    "    i+=1\n",
    "    \n",
    "lgd = plt.legend(loc=1, prop={'size': 14}, bbox_to_anchor=(1.1, 1.05))\n",
    "FILEPATH = 'Figures/'\n",
    "FILENAME = 'TEMPORARY_Perturbed_'+str(n_hours)+'_timespan_switched_'+str(ind1)+'_'+str(ind2)+'_t_switch_'+str(tp0)+'_'+str(tp1)+'_'+str(day)+'_alpha_'+str(alpha)+'.png'\n",
    "\n",
    "#plt.savefig(FILEPATH+FILENAME, dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCS MATRICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_sim(A,B):\n",
    "    norm_A = math.sqrt(sum([x**2 for x in A]))\n",
    "    norm_B = math.sqrt(sum([x**2 for x in B]))\n",
    "    return np.dot(A,B)/(norm_A*norm_B)\n",
    "\n",
    "\n",
    "def cosine_sim_graph_out(i,g1,g2):\n",
    "    if i in g1.nodes() and i in g2.nodes():\n",
    "        neigh1 = set(g1.neighbors(i))\n",
    "        neigh2 = set(g2.neighbors(i))\n",
    "      #  print(neigh1,neigh2)\n",
    "        norm1 = math.sqrt(sum([g1.get_edge_data(i,j)['weight']**2 for j in neigh1]))\n",
    "        norm2 = math.sqrt(sum([g2.get_edge_data(i,j)['weight']**2 for j in neigh2]))\n",
    "        numerator = sum([g1.get_edge_data(i,j)['weight']*g2.get_edge_data(i,j)['weight'] \n",
    "                         for j in neigh1.intersection(neigh2)])\n",
    "    else:\n",
    "        norm1, norm2, numerator = 1, 1, 0\n",
    "    return numerator/(norm1*norm2)\n",
    "\n",
    "def cosine_sim_graph_in(i,g1,g2):\n",
    "    if i in g1.nodes() and i in g2.nodes():\n",
    "        neigh1 = set(g1.neighbors(i))\n",
    "        neigh2 = set(g2.neighbors(i))\n",
    "      #  print(neigh1,neigh2)\n",
    "        norm1 = math.sqrt(sum([g1.get_edge_data(j,i)['weight']**2 for j in neigh1]))\n",
    "        norm2 = math.sqrt(sum([g2.get_edge_data(j,i)['weight']**2 for j in neigh2]))\n",
    "        numerator = sum([g1.get_edge_data(j,i)['weight']*g2.get_edge_data(j,i)['weight'] \n",
    "                         for j in neigh1.intersection(neigh2)])\n",
    "    else:\n",
    "        norm1, norm2, numerator = 1, 1, 0\n",
    "    return numerator/(norm1*norm2)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global cosine similarity \n",
    "gcs = {}\n",
    "\n",
    "listtimes = sorted(g.keys())\n",
    "\n",
    "for t1 in listtimes:\n",
    "    for t2 in listtimes:\n",
    "        #if t1>=t2:\n",
    "        #    continue\n",
    "        list_w1 = []\n",
    "        list_w2 = []\n",
    "        \n",
    "        g1 = g[t1]\n",
    "        g2 = g[t2]\n",
    "        \n",
    "        setnodes1 = set(g1.nodes())\n",
    "        setnodes2 = set(g2.nodes())\n",
    "        setnodes = setnodes1.union(setnodes2)\n",
    "        \n",
    "        edges = set(g1.edges()).intersection(set(g2.edges()))\n",
    "        for i,j in edges:\n",
    "            list_w1.append(g1.get_edge_data(i,j)['weight'])\n",
    "            list_w2.append(g2.get_edge_data(i,j)['weight'])\n",
    "        \n",
    "        gcs[(t1,t2)] = cosine_sim(list_w1,list_w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listtimes = sorted(g.keys())\n",
    "\n",
    "#COMPUTE THE MATRIX\n",
    "\n",
    "arraygcs = []\n",
    "for t1 in listtimes:\n",
    "    arraygcs.append([gcs[(t1,t2)] for t2 in listtimes])\n",
    "\n",
    "arraygcs = np.array(arraygcs)\n",
    "np.save('../GCS_VALUES_2_PARAMETERS_TEMPORARY_Perturbed_'+str(n_hours)+'_timespan_switched_'+str(ind1)+'_'+str(ind2)+'_t_switch_'+str(tp0)+'_'+str(tp1)+'_'+str(day)+'_alpha_'+str(alpha)+'_beta_'+str(beta)+'_BABOONS_DATA', arraygcs)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9,7))\n",
    "\n",
    "# VISUALIZATION AND LIMITS\n",
    "\n",
    "cmapProp = {'drawedges': False,}\n",
    "m = ax.imshow(arraygcs, cmap=plt.cm.get_cmap('gnuplot2'), vmin=0, vmax=1)\n",
    "cbar = ax.figure.colorbar(m, ax=ax, **cmapProp)\n",
    "cbar.ax.tick_params(labelsize=18) \n",
    "\n",
    "\n",
    "ax.hlines([tp0-0.5], *ax.get_xlim())\n",
    "ax.vlines([tp0-0.5], *ax.get_xlim())\n",
    "\n",
    "\n",
    "ax.hlines([tp1-0.5], *ax.get_xlim(), color='red')\n",
    "ax.vlines([tp1-0.5], *ax.get_xlim(), color='red')\n",
    "\n",
    "ax.set_yticks(range(len(listtimes))[::5])\n",
    "ax.set_yticklabels(range(1,len(listtimes)+1)[::5],rotation=20, fontsize=18)\n",
    "\n",
    "ax.set_xticks(range(len(listtimes))[::5])\n",
    "ax.set_xticklabels(range(1,len(listtimes)+1)[::5],rotation=20, fontsize=18)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "FILEPATH = 'Figures/'\n",
    "FILENAME = 'GCS_MATRIX_Perturbed_'+str(n_hours)+'_timespan_switched_'+str(ind1)+'_'+str(ind2)+'_t_switch_'+str(tp0)+'_'+str(tp1)+'_'+str(day)+'_alpha_'+str(alpha)+'_beta_'+str(beta)+'_BABOONS_DATA.png'\n",
    "\n",
    "\n",
    "plt.savefig(FILEPATH+FILENAME)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
